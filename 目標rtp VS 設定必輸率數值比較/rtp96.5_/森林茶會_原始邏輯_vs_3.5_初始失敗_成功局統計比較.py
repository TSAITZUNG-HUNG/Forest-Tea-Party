import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# è¨­å®š matplotlib å­—é«”æ”¯æ´ä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']

# === æ¨¡æ“¬è¨­å®š ===
TARGET_RTP = 0.965
MAX_MULTIPLIER = 1_000_000
BATCH_SIZE = 1000
REPEATS = 20
MIN_STEP = 1
MAX_STEP = 25
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

# å€ç‡æ± ï¼ˆ25 é¡†ï¼‰
full_pool_np = np.array([1.25]*9 + [1.5]*6 + [2.0]*4 + [3.0]*3 + [5.0]*3, dtype=np.float32)

# éé—œæ©Ÿç‡è¨ˆç®—å…¬å¼
def compute_probs(sampled_tensor):
    a = (sampled_tensor == 1.25).sum(dim=1)
    b = (sampled_tensor == 1.5).sum(dim=1)
    c = (sampled_tensor == 2.0).sum(dim=1)
    d = (sampled_tensor == 3.0).sum(dim=1)
    e = (sampled_tensor == 5.0).sum(dim=1)
    return TARGET_RTP * (1/1.25)**a * (1/1.5)**b * (1/2.0)**c * (1/3.0)**d * (1/5.0)**e

# æ¨¡æ“¬ä¸»å‡½æ•¸
def simulate_with_logic(logic_name, early_fail_rate=0.0):
    results = []
    for step in range(MIN_STEP, MAX_STEP + 1):
        all_success = 0
        all_reward = 0.0
        mean_list, std_list = [], []

        for _ in range(REPEATS):
            sampled_np = np.array([
                np.random.choice(full_pool_np, size=step, replace=False)
                for _ in range(BATCH_SIZE)
            ], dtype=np.float32)
            sampled = torch.tensor(sampled_np, device=device)
            probs = compute_probs(sampled)

            if early_fail_rate > 0:
                gate = torch.rand(BATCH_SIZE, device=device)
                probs *= (gate > early_fail_rate)

            rand_vals = torch.rand(BATCH_SIZE, device=device)
            is_win = rand_vals <= probs

            multipliers = torch.prod(sampled * is_win[:, None], dim=1)
            multipliers = torch.clamp(multipliers, max=MAX_MULTIPLIER)

            rewards = multipliers[multipliers > 0].cpu().numpy()
            mean_list.append(rewards.mean() if len(rewards) > 0 else 0.0)
            std_list.append(rewards.std() if len(rewards) > 0 else 0.0)

            all_success += is_win.sum().item()
            all_reward += multipliers.sum().item()

        avg_rtp = all_reward / (BATCH_SIZE * REPEATS)
        results.append({
            "è¸©æ­¥æ•¸": step,
            "å¹³å‡å€æ•¸": np.mean(mean_list),
            "æ¨™æº–å·®": np.mean(std_list),
            "å¯¦éš›RTP": avg_rtp,
            "é‚è¼¯": logic_name
        })
    return results

# åŸ·è¡Œæ¨¡æ“¬
results_orig = simulate_with_logic("åŸå§‹é‚è¼¯", early_fail_rate=0.0)
results_7 = simulate_with_logic("3.5%åˆå§‹å¤±æ•—", early_fail_rate=1 - TARGET_RTP)

# æ•´åˆçµæœèˆ‡è¼¸å‡º Excel
df_all = pd.DataFrame(results_orig + results_7)
excel_path = "æ£®æ—èŒ¶æœƒ_åŸå§‹é‚è¼¯_vs_3.5%åˆå§‹å¤±æ•—_æˆåŠŸå±€çµ±è¨ˆæ¯”è¼ƒ.xlsx"
df_all.to_excel(excel_path, index=False)
print(f"ğŸ“„ å·²å„²å­˜ï¼š{excel_path}")

# é›™è»¸åœ–ï¼šRTPï¼ˆå·¦è»¸ï¼‰èˆ‡æ¨™æº–å·®ï¼ˆå³è»¸ï¼‰
fig, ax1 = plt.subplots(figsize=(14, 6))
colors = {'åŸå§‹é‚è¼¯': 'tab:blue', '3.5%åˆå§‹å¤±æ•—': 'tab:green'}

# å·¦è»¸ï¼šRTP
for logic in df_all["é‚è¼¯"].unique():
    df_sub = df_all[df_all["é‚è¼¯"] == logic]
    ax1.plot(df_sub["è¸©æ­¥æ•¸"], df_sub["å¯¦éš›RTP"], marker='o', color=colors[logic], label=f"{logic} - RTP")
ax1.axhline(TARGET_RTP, color='red', linestyle='--', label=f"ç†è«– RTP = {TARGET_RTP}")
ax1.set_xlabel("è¸©æ­¥æ•¸")
ax1.set_ylabel("å¯¦éš› RTP", color='black')
ax1.tick_params(axis='y', labelcolor='black')

# å³è»¸ï¼šæ¨™æº–å·®
ax2 = ax1.twinx()
for logic in df_all["é‚è¼¯"].unique():
    df_sub = df_all[df_all["é‚è¼¯"] == logic]
    ax2.plot(df_sub["è¸©æ­¥æ•¸"], df_sub["æ¨™æº–å·®"], marker='s', linestyle='--', color=colors[logic], label=f"{logic} - æ¨™æº–å·®")
ax2.set_ylabel("æˆåŠŸå±€å€æ•¸æ¨™æº–å·®", color='black')
ax2.tick_params(axis='y', labelcolor='black')

# åœ–ä¾‹æ•´åˆ
lines_1, labels_1 = ax1.get_legend_handles_labels()
lines_2, labels_2 = ax2.get_legend_handles_labels()
ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc="upper left")

plt.title("æ¯è¸©æ­¥æ•¸çš„å¯¦éš› RTP èˆ‡æˆåŠŸå±€å€æ•¸æ¨™æº–å·®ï¼ˆé›™è»¸æ¯”è¼ƒï¼‰")
plt.grid(True)
plt.tight_layout()
plt.show()
