import torch
import pandas as pd
import numpy as np
import os

# === æ¨¡æ“¬è¨­å®š ===
TARGET_RTP = 0.985
MAX_MULTIPLIER = 1_000_000
batch_size = 50_000
min_step = 1
max_step = 25
rounds = 10_000
sims_per_round = 10_000
output_dir = "æ£®æ—èŒ¶æœƒ_çˆ†ç‚¸å€ç‡é¢¨éšª_98.5"
os.makedirs(output_dir, exist_ok=True)

# GPU è£ç½®
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

# å€ç‡æ± ï¼ˆ25 é¡†ï¼‰
full_pool_np = np.array(
    [1.25] * 9 + [1.5] * 6 + [2.0] * 4 + [3.0] * 3 + [5.0] * 3,
    dtype=np.float32
)

# æ©Ÿç‡è¨ˆç®—
def compute_probs(shuffled_tensor):
    a = (shuffled_tensor == 1.25).sum(dim=1)
    b = (shuffled_tensor == 1.5).sum(dim=1)
    c = (shuffled_tensor == 2.0).sum(dim=1)
    d = (shuffled_tensor == 3.0).sum(dim=1)
    e = (shuffled_tensor == 5.0).sum(dim=1)
    return TARGET_RTP * (1 / 1.25)**a * (1 / 1.5)**b * (1 / 2.0)**c * (1 / 3.0)**d * (1 / 5.0)**e

# ä¸»è¿´åœˆ
for step in range(min_step, max_step + 1):
    print(f"\nğŸš€ é–‹å§‹æ¨¡æ“¬ è¸©{step}ï¼ˆå…± {rounds * sims_per_round:,} å±€ï¼‰")
    rtp_list = []
    all_rewards = []

    for r in range(rounds):
        total_reward = 0.0
        total_sims = 0

        for i in range(0, sims_per_round, batch_size):
            sims = min(batch_size, sims_per_round - i)
            sampled_np = np.array([
                np.random.choice(full_pool_np, size=step, replace=False)
                for _ in range(sims)
            ], dtype=np.float32)
            sampled = torch.tensor(sampled_np, device=device)
            probs = compute_probs(sampled)
            rand_vals = torch.rand(sims, device=device)
            is_win = rand_vals <= probs
            multipliers = torch.prod(sampled * is_win[:, None], dim=1)
            multipliers = torch.clamp(multipliers, max=MAX_MULTIPLIER)
            total_reward += multipliers.sum().item()
            total_sims += sims
            rewards_np = multipliers[multipliers > 0].cpu().numpy()
            all_rewards.extend(rewards_np)

        rtp = total_reward / total_sims
        rtp_list.append(rtp)
        if (r + 1) % 1000 == 0:
            print(f"  âœ… å®Œæˆ {r + 1:,} / {rounds:,} è¼ªï¼Œç•¶å‰ RTPï¼š{rtp:.6f}")

    # çµ±è¨ˆ
    rewards_np = np.array(all_rewards)
    mean_multiplier = rewards_np.mean() if len(rewards_np) > 0 else 0.0
    std_multiplier = rewards_np.std() if len(rewards_np) > 0 else 0.0
    percentiles = np.percentile(rewards_np, q=range(1, 100)) if len(rewards_np) > 0 else np.zeros(99)
    rtp_np = np.array(rtp_list)
    summary = {
        "è¸©æ­¥æ•¸": step,
        "æ¨¡æ“¬å±€æ•¸": rounds * sims_per_round,
        "RTP å¹³å‡å€¼": rtp_np.mean(),
        "RTP æ¨™æº–å·®": rtp_np.std(),
        "æœ€å° RTP": rtp_np.min(),
        "æœ€å¤§ RTP": rtp_np.max(),
        "æˆåŠŸå±€å¹³å‡å€æ•¸": mean_multiplier,
        "æˆåŠŸå±€æ¨™æº–å·®": std_multiplier,
        **{f"{p}% å€æ•¸": val for p, val in zip(range(1, 100), percentiles)}
    }

    df_step = pd.DataFrame([summary])
    file_path = os.path.join(output_dir, f"æ£®æ—èŒ¶æœƒ_è¸©{step}_çˆ†ç‚¸å€ç‡é¢¨éšª_98.5.xlsx")
    df_step.to_excel(file_path, index=False)
    print(f"ğŸ“„ è¸©{step} çµ±è¨ˆå ±è¡¨å·²å„²å­˜ï¼š{file_path}")

    # æ¸…é™¤è¨˜æ†¶é«”
    del all_rewards, rewards_np, rtp_np
    torch.cuda.empty_cache() if torch.cuda.is_available() else None
